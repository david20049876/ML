import numpy as np
from matplotlib import pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn import datasets
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, tree
import graphviz

# Load iris dataset and prepare data for Decision Tree Classifier
iris = datasets.load_iris()
X = iris.data[:, 2:]
y = iris.target

# Fit the Decision Tree Classifier
clf = DecisionTreeClassifier(max_depth=2, random_state=1234)
model = clf.fit(X, y)

# Export and print the decision tree as text
text_representation = tree.export_text(clf)
print(text_representation)

# Save text representation to a file
with open("decision_tree.log", "w") as f_out:
    f_out.write(text_representation)

# Predict probability of a class
print(clf.predict_proba([[5, 1.5]]))

# Predict a class
print(clf.predict([[5, 1.5]]))

# Fit a second decision tree with hyperparameters
tree_clf2 = DecisionTreeClassifier(max_depth=2, min_samples_leaf=1, min_samples_split=2, random_state=2)
tree_clf2.fit(X, y)

# Function to plot decision boundaries
def plot_decision_boundary(clf, X, y, axes=[0, 7.5, 0, 3], iris=True, legend=False, plot_training=True):
    x1s = np.linspace(axes[0], axes[1], 100)
    x2s = np.linspace(axes[2], axes[3], 100)
    x1, x2 = np.meshgrid(x1s, x2s)
    X_new = np.c_[x1.ravel(), x2.ravel()]
    y_pred = clf.predict(X_new).reshape(x1.shape)
    custom_cmap = ListedColormap(['#fafab0', '#9898ff', '#a0faa0'])
    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)
    
    if plot_training:
        plt.plot(X[:, 0][y == 0], X[:, 1][y == 0], "yo", label="Iris setosa")
        plt.plot(X[:, 0][y == 1], X[:, 1][y == 1], "bs", label="Iris versicolor")
        plt.plot(X[:, 0][y == 2], X[:, 1][y == 2], "g^", label="Iris virginica")
    
    plt.axis(axes)
    if iris:
        plt.xlabel("Petal length", fontsize=14)
        plt.ylabel("Petal width", fontsize=14)
    if legend:
        plt.legend(loc="lower right", fontsize=14)

# Plot decision boundaries
plt.figure(figsize=(8, 4))
plot_decision_boundary(clf, X, y)
plt.title("Decision Tree (max_depth=2)", fontsize=16)
plt.show()

# Load California housing dataset for regression
from sklearn.datasets import fetch_california_housing
housing = fetch_california_housing()
X = housing.data
y = housing.target

# Fit the Decision Tree Regressor
dt = DecisionTreeRegressor(max_depth=3, random_state=1234)
model = dt.fit(X, y)

# Export and print the decision tree as text
text_representation = tree.export_text(dt, feature_names=housing.feature_names)
print(text_representation)

# Visualize the decision tree
fig = plt.figure(figsize=(15, 10))
_ = tree.plot_tree(dt, feature_names=housing.feature_names, filled=True)

# Save the figure
fig.savefig("decision_tree_regression.png")

plt.show()
